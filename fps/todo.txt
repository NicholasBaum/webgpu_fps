pbr render
    - load normal mapped cube
    - check on 16bit maps usage
    - shadowfactor is missing    
    - implement alternative mode in prefiltered shader / see here for mip creation https://greggman.github.io/webgpu-utils/
refactor ModelAsset see below
load 3d models
resizable canvas
try to copy these images https://www.rombo.tools/2021/11/26/interfaced-lambertians/
3d scan fancy tea saucers and render

area light
deffered rendering
raytraced shadows
cleanup architecture too man piepline builder files...
implement screenspace reflection
implement screenspace gi
implement cryengine lightning



https://nicholasbaum.github.io/webgpu_fps/


Done
    Irradiance Map Builder
    Target Light
    Shadow Maps
    UV Tiling
    Normal Mapping
    Ui
    Multiple Lights
    Blinn-Phong Shader
    Implemented Texturing with MipMaps
    Instance Rendering
    Box and Pipe Geometry with Normals
    
    
    
Remark
    -   implement cascaded shadowmaps and/or variance shadow map
        ideas for better shadow maps: choose bias by angle, use backface culling, better light view determination
        acutally simply offsetting the vertices by its normal worked, atm it's a constant offset value,
        probably should depend on scene size, shadow map size in view or worlspace...
    -   merging shaders by string concatenation, could be fixed by some more sophisticated string substitution module (preprocessor)
        with some error message interception to fix the wrong line numbers (see https://jsgist.org/?src=cb4acc6a854a7176e88af7e6a145130d)
        only the last group of a shader can be left unset what isn't really helpful
    -   normal map rendering and ambient don't work to well together as when you have no light only the ambient is rendered
        but no normal map effect is visible this happens in shadow map cases and when surface isn't facing a light
    -   as far as i understood fragment shaders always output rgba and if the target has bgra8unorm format it will be converted automatically

Backlog
    -   implement hdr file loader. At the moment i can only use 64bit pngs.
        https://github.com/mrdoob/three.js/blob/master/examples/jsm/loaders/RGBELoader.js#L421
        https://github.com/DerSchmale/io-rgbe
        https://github.com/vorg/parse-hdr/blob/master/index.js
    -   handle TODO in code base
    -   load another scene probably shouldn't recreate the Engine. Probably implies some redesign more abstract buffer writer classes etc.
    -   target light needs a sophisticated near/far plane value determination
    -   Depthmap viewer with sliders for near far plane values in texture_renderer.wgsl, alternatively deduce good values from scene
    -   Omni/Point Light Shadow includes using a cubemap
    -   Shadows from NormalMap
    -   Shadow Voulumes
    -   Raytraced Shadows
    -   renderer/pipeline builder could compose BindGroup instead of GPUBuffers, meaning types lile Material hold BindGroups instead of buffer,
        but can't see much of an advantage at the moment

    -   move material from assett to instance 
        need to use the texture_2d_array type for multiple texture maps        
    
    -   create smoothed tangent vectors like in the rust webgpu normalmap example

    -   parralax mapping
        https://webgpu.github.io/webgpu-samples/samples/normalMap#./normalMap.wgsl


- loading hdr images has an explanation in the comments section of the following link
    https://webgpufundamentals.org/webgpu/lessons/webgpu-textures.html
    search:Note, because the polyfill is not actually a typedarray directy (it has ...
  https://stackoverflow.com/questions/77032862/load-hdr-10-bit-avif-image-into-a-rgba16float-texture-in-webgpu

  idea is to convert a hdr to avif, avif actually should be loadable, but above links says it doesn't work, need to test, perhaps it works in 2024
  haven't yet found out how to convert a hdr to avif, but above linke has a downloadable test image

 to test if a hdr was correctly loaded one can subtract 1 from the values in a shader, if the result is black everyting was clamped


  // Fetch the HDR image and create an ImageBitmap
async function loadImageBitmap(url) {
  const res = await fetch(url);
  const blob = await res.blob();
  return await createImageBitmap(blob, {
    colorSpaceConversion: 'none',
  });
}

// Create a texture
const texture = device.createTexture({
  label: 'HDR Texture',
  format: 'rgba16unorm',
  size: [imageBitmap.width, imageBitmap.height],
  usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT,
});

// Copy the ImageBitmap to the texture
device.queue.copyExternalImageToTexture(
  { source: imageBitmap },
  { texture },
  { width: imageBitmap.width, height: imageBitmap.height }
);



ModelAsset:
improve reusability of redundant gpu data
perhaps get ride of ModelAsset and only use ModelInstance holding the following VertexBuffer type and Material
implement a VertexBuffer type holding all data concering a vertexbuffer
analog with Texture
refactor Material to use the new Texture type 
refactor ModelAsset to use VertexBuffer and Material 