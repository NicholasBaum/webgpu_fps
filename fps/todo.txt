unify blinn phon shader with optional normal and shadowmap    
    normal map optionality is straight forward
clean up/merge pipelinde creation stuff
moving objects
outsouce shadowmap calc to fn
use filter in shadowmap
light_mat can be stored in Light class initially and perhaps keep it there with an index corresponding to a texture slot

check if i really have to create dummy maps for unbound resources
check if individiual shaders might be better for e.g. shadow and none shadow maps

more sophisticated lightview creation in ShadowMapRenderer
    check how do calc go view range    
v1 of shadowmap optionality will have to use an array of light_mats and a low fixed count of shadowmaps because i havent testet texture array oder megatextures yet

transform updates have to be made before renderers are called
do some none linear scaling in TextureRendering
moving lights
multiple lights/multiple shadows 

pbr render
load 3d models
resizable canvas
3d scan fancy tea saucers and render

deffered rendering
raytraced shadows
implement screenspace reflection
implement screenspace gi
implement cryengine lightning



https://nicholasbaum.github.io/webgpu_fps/


Done
    UV Tiling
    Normal Mapping
    Ui
    Multiple Lights
    Blinn-Phong Shader
    Implemented Texturing with MipMaps
    Instance Rendering
    Box and Pipe Geometry with Normals
    
    
    
Remark
    -   normal map rendering and ambient don't work to well together as when you have no light only the ambient is rendered
        but no normal map effect is visible this happens in shadow map cases and when surface isn't facing a light
        
    -   if you load a texture as e.g. srgb the sampler converts it to linear space automatically
        krita tells me my textures are in srgb space but loading them as srgb didn't have any visible changes


Backlog
    -   Shadow Voulumes
    -   Raytraced Shadows
    -   renderer/pipeline builder could compose BindGroup instead of GPUBuffers, meaning types lile Material hold BindGroups instead of buffer,
        but can't see much of an advantage at the moment

    -   move material from assett to instance,
        textures can't be placed in structs and an array of textures isn't allowed either, i think
        so you ll have to run multiple passes to render the same asset with different textures
        obviously you only have to rebind different combinations of vertex data and materials
        the none texture related material data coul be moved into the instance struct
    
    -   create smoothed tangent vectors like in the rust webgpu normalmap example

    -   parralax mapping
        https://webgpu.github.io/webgpu-samples/samples/normalMap#./normalMap.wgsl