environtment mapping is important for good metallic renders, check how metallic reflections actually work and if this can be Implemented before PBR


pbr render
load 3d models
resizable canvas
3d scan fancy tea saucers and render

area light
deffered rendering
raytraced shadows
implement screenspace reflection
implement screenspace gi
implement cryengine lightning



https://nicholasbaum.github.io/webgpu_fps/


Done
    Target Light
    Shadow Maps
    UV Tiling
    Normal Mapping
    Ui
    Multiple Lights
    Blinn-Phong Shader
    Implemented Texturing with MipMaps
    Instance Rendering
    Box and Pipe Geometry with Normals
    
    
    
Remark
    -   implement cascaded shadowmaps and/or variance shadow map
        ideas for better shadow maps: choose bias by angle, use backface culling, better light view determination
        acutally simply offsetting the vertices by its normal worked, atm it's a constant offset value,
        probably should depend on scene size, shadow map size in view or worlspace...
    -   merging shaders by string concatenation, could be fixed by some more sophisticated string substitution module (preprocessor)
        with some error message interception to fix the wrong line numbers (see https://jsgist.org/?src=cb4acc6a854a7176e88af7e6a145130d)
        only the last group of a shader can be left unset what isn't really helpful
    -   normal map rendering and ambient don't work to well together as when you have no light only the ambient is rendered
        but no normal map effect is visible this happens in shadow map cases and when surface isn't facing a light
        
    -   if you load a texture as e.g. srgb the sampler converts it to linear space automatically
        krita tells me my textures are in srgb space but loading them as srgb didn't have any visible changes


Backlog
    -   handle TODO in code base
    -   target light needs a sophisticated near/far plane value determination
    -   Depthmap viewer with sliders for near far plane values in texture_renderer.wgsl, alternatively deduce good values from scene
    -   Omni/Point Light Shadow includes using a cubemap
    -   Shadows from NormalMap
    -   Shadow Voulumes
    -   Raytraced Shadows
    -   renderer/pipeline builder could compose BindGroup instead of GPUBuffers, meaning types lile Material hold BindGroups instead of buffer,
        but can't see much of an advantage at the moment

    -   move material from assett to instance 
        need to use the texture_2d_array type for multiple texture maps        
    
    -   create smoothed tangent vectors like in the rust webgpu normalmap example

    -   parralax mapping
        https://webgpu.github.io/webgpu-samples/samples/normalMap#./normalMap.wgsl